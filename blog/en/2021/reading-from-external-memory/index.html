<!DOCTYPE html><html lang=en> <head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>A journey to io_uring, AIO and modern storage devices</title><link rel="shortcut icon" href=/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/images/logo-180x180.png><meta property=og:title content="A journey to io_uring, AIO and modern storage devices"><meta property=og:description content="While main memory is considered to be rather cheap by some systems designers it is not always possible to store everythi"><meta property=og:type content=article><meta property=og:image content=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/all-single-read.png><meta content=https://clickhouse.tech/blog/en/2021/reading-from-external-memory/ property=og:url><link href=https://clickhouse.tech/blog/en/2021/reading-from-external-memory/ rel=canonical><link rel=search href=/opensearch.xml title=ClickHouse type=application/opensearchdescription+xml><script type=application/ld+json>[{
"@context": "http://schema.org",
"@type": "BlogPosting",
"headline": "A journey to io_uring, AIO and modern storage devices",
"mainEntityOfPage": "https://clickhouse.tech/blog/en/2021/reading-from-external-memory/",

"datePublished": "2021-03-09",
"dateModified": "2021-03-09",

"image": "https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/all-single-read.png",
"author": {
  "@type": "Project",
  "name": "ClickHouse"
},
"publisher": {
  "@type": "Organization",
  "name": "Yandex LLC",
  "logo": {
    "@type": "ImageObject",
    "url": "https://clickhouse.tech/images/yandex.png",
    "width": 163,
    "height": 60
  }
}}]</script><meta name=description content="While main memory is considered to be rather cheap by some systems designers it is not always possible to store everythi"><meta name=keywords content="Linux, benchmark, experiment"><link rel=alternate type=application/rss+xml href=https://clickhouse.tech/blog/en/rss.xml><link href=/css/base.css?e27f3458 media=all rel=stylesheet></head> <body dir=ltr class=blog> <nav id=top-nav class="navbar navbar-expand-md mb-3"> <div class="container justify-content-between"> <a href=/ class="d-block navbar-brand mr-3 text-reset"> <img id=docs-logo-icon src=/images/logo.svg alt="ClickHouse logo" title="ClickHouse logo"> </a> <div class="w-100 navbar-text text-left d-none d-md-block"> <h2 class="display-6 m-0 p-0 d-inline"> <a href=/blog/en/ class="text-reset text-decoration-none"> ClickHouse Blog </a> </h2> </div> <div class="d-none d-md-block"> <ul class="navbar-nav ml-auto mt-2 mt-lg-0 justify-content-end"> <li class=nav-item> <a class="nav-link text-reset" href=https://github.com/ClickHouse/ClickHouse/tree/master/website/blog rel="external nofollow noreferral" target=_blank> New&nbsp;post </a> </li> <li class=nav-item> <a href=/docs/en/ class="nav-link text-reset"> Documentation </a> </li> <li class=nav-item> <a class="nav-link text-reset" href=https://github.com/ClickHouse/ClickHouse rel="external nofollow noreferrer" target=_blank> GitHub </a> </li> <li id=languages-wrapper class="nav-item dropdown"> <div id=languages-dropdown> <a class="nav-link dropdown-toggle d-inline-block text-reset" href=# id=lang-dropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false> <img src=/images/flags/en.svg alt=English title=English width=32 class="d-inline-block mt-n1"> </a> <div class=dropdown-menu aria-labelledby=lang-dropdown> <a href=/blog/en/ class="dropdown-item text-reset disabled"> <img src=/images/flags/en.svg alt title width=32 class="d-inline-block mr-2"> English </a> <a href=/blog/ru/ class="dropdown-item text-reset "> <img src=/images/flags/ru.svg alt title width=32 class="d-inline-block mr-2"> Русский </a> </div> </div> </li> </ul> </div> </div> </nav> <div class=container> <div class=row> <div id=content-wrapper class=col> <div id=content> <header class=text-center> <img class="img-fluid mb-3" src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/all-single-read.png alt="A journey to io_uring, AIO and modern storage devices" title="A journey to io_uring, AIO and modern storage devices"> <h1 class="display-4 mb-3">A journey to io_uring, AIO and modern storage devices</h1> </header> <div class=row> <article class="col-md-10 offset-1"> <p><em>While main memory is considered to be rather cheap by some systems designers it is not always possible to store everything in the main memory. When data is stored in external memory one has to think carefully how to access the data. There are several kind of storage devices and more than one system call to read from them. We performed experiments to find out how different Linux system calls perform for available devices. In total HDD, SATA SSD, NVMe SSD, and Intel Optane were accessed via single-threaded and multi-threaded pread, Linux aio, and new io_uring interfaces. Full report is available in PDF format:</em> <a href=https://arxiv.org/pdf/2102.11198 rel="external nofollow noreferrer" target=_blank>link</a>. <em>We give one section from the report as an example.</em></p> <h1 id=single-random-read>Single Random Read<a class=headerlink href=#single-random-read title="Permanent link"> </a></h1> <p>External memory devices are block devices which means data transfer between a device and a host is done in blocks rather than single bytes. Typically 512 bytes or 4 kilobytes blocks are used. These block sizes have been chosen by manufactures long time ago and may be not the best choice for modern devices. By requesing larger amount of contigious data we can emulate larger block size. Let's find out how modern devices perform with larger blocks.</p> <p>Our goal is to pick the best block size for a random read. An application (or filesystem) can pick any block size and access data with respect to this block size. We vary block size from 4 kilobytes up to 32 megabytes. For each block size we make some random reads. Among these reads we calculate average, minimum and maximum latency as well as 99,0 and 99,9 percentiles. We use system call pread(2) in this experiment. We believe that lseek(2) followed by read(2) should have the same performance since the observed storage access time is far longer than a system call.</p> <h2 id=hard-disk-drive>Hard Disk Drive<a class=headerlink href=#hard-disk-drive title="Permanent link"> </a></h2> <p>This figure shows results for HDD.</p> <p><img alt="HDD single read latency" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/hdd-single-read.png></p> <p>The latency is almost the same for all block sizes smaller than 256 kilobytes. This happens because seek time is much larger than the data transfer time. The seek time includes arm positioning to find the right track and awaiting for platter rotation to bring data under the head. A simple consequence is that for a HDD random read one should use blocks of size at least 256 kilobytes. Even if an application use smaller blocks the drive access time would be the same. However one could still decide to use smaller blocks for better cache utilization: if the amount of data per request is small and is expected to fit in cache then storing a large block along with the requested data would actually make cache capacity smaller in terms of useful data.</p> <p>The 256 kilobyte block read takes 12 milliseconds on the average. We experienced variations from 4 milliseconds up to 25 milliseconds. This is really a huge amount of time for a computer. For example the typical process scheduling quantum is just a few milliseconds. An operating system can (and in fact does) execute other processes while our process waits for the data to arrive from the hard drive.</p> <h2 id=sata-ssd>SATA SSD<a class=headerlink href=#sata-ssd title="Permanent link"> </a></h2> <p>The figure below shows SATA SSD read latencies.</p> <p><img alt="SATA SSD single read latency" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/ssd-single-read.png></p> <p>Note that the time at the lower part of the figure is in microseconds (we use standard shortenings ms for milliseconds and us for microseconds). Reading block of size 4 kilobytes takes 140 microseconds on the average and the time growth is linear when the block size increase. Compared to HDD reading a 4 kilobyte block from SSD is 80 times faster. For a 256 kilobyte block SSD is ten times faster than HDD. When block size is large enough (starting from 4 megabytes) SSD is only two times faster than HDD.</p> <h2 id=nvme-ssd>NVMe SSD<a class=headerlink href=#nvme-ssd title="Permanent link"> </a></h2> <p>The next figure shows results for NVMe SSD.</p> <p><img alt="NVMe SSD single read latency" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/nvme-single-read.png></p> <p>The latency is better than those for SATA SSD. For a 4 kilobytes block size the average time improved only a little, but the 99 percentile is two times lower. It takes less than millisecond to read a megabyte block from NVMe SSD. For SATA SSD it took 3 milliseconds. As we see, upgrade from SATA SSD to NVMe SSD is not as dramatic as upgrade from HDD to SATA SSD. This is not surprising since both SATA and NVMe SSD are based on the same thechnology. Only interfaces differ.</p> <h2 id=intel-optane>Intel Optane<a class=headerlink href=#intel-optane title="Permanent link"> </a></h2> <p>This figure shows results for Intel Optane SSD.</p> <p><img alt="Intel Optane single read latency" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/optane-single-read.png></p> <p>Minimal latency is 12 microseconds whih is 10 times lower than those of NVMe SSD. Average latency is 1000 lower than those of HDD. There is quite large variation for small block read latency: even though the average time is quite low and close to minimal latency the maximum latency and even 99 percentile are significantly worse. If somebody looks at these results and wishes to create an Intel Optane-based service with 12 microsecond latency for reads they would have to install larger number of Intel Optane drives or consider providing more realistic timings.</p> <p>When latency is so small overheads of context switching and interrupt handling become noticeable. One can use polling mode to gain some improvement. In this mode the Linux kernel monitors the completion queue instead of switching to some other job and relying on hardware interrupt with interrupt handler to notify about completion. Clearly, it is considerable to use the polling mode only when hardware response is expected to arrive fast enough.<br> <img alt="Intel Optane single read latency in polling mode" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/optane-single-hipri-read.png></p> <p>The figure above shows results for reading from Intel Optane in polling mode. The polling mode is used when an application calls preadv2(2) system call with RWF_HIGHPRI flag. Compared to usual pread(2) the polling mode lowers the maximum latency by a factor of two for block sizes up to 256 kilobytes.</p> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link"> </a></h2> <p>To summarize our results the next figure shows single read latencies for all four storage types on a single chart.</p> <p><img alt="Single read latency for Optane, SSD and HDD" class=img-fluid src=https://blog-images.clickhouse.tech/en/2021/reading-from-external-memory/all-single-read.png></p> <p>Starting from 4 megabytes the latency is easily predicted by linear extrapolation so we don't show larger blocks here. To show everything on a single figure we are forced to use quite an overloaded legend. We use vertical level to show the latency and we iterate the block size horizontally. For each block size we show four bars, from left to right: for Intel Optane, NVMe SSD, SATA SSD, and HDD. Storage type is represented by hatch and the latency by color.</p> <p>We see that solid state device latencies are far better than HDD. For a single read the leader is Intel Optane, however as we shall see later it has it's own drawback compared to NVMe SSD. NVMe SSD and SATA SSD look quite close to each other when the block size is small. Our observations show that the best block size for random read is 256 kilobytes for HDD, 4 kilobytes for NVMe and SATA SSD and 8 kilobytes for Intel Optane.</p> <p>So, how about testing modern IO interfaces in Linux? Continue reading the <a href=https://arxiv.org/pdf/2102.11198 rel="external nofollow noreferrer" target=_blank>full article</a>.</p> <p>2021-03-09 <a href=https://github.com/savrus rel="external nofollow noreferrer" target=_blank>Ruslan Savchenko</a></p> </article> <section class="d-none d-md-block col-md-1 mh-100"> <div class="sticky-top pt-2"> <a class="d-block mb-2" href="https://twitter.com/intent/tweet?url=A%20journey%20to%20io_uring%2C%20AIO%20and%20modern%20storage%20devices+https%3A//clickhouse.tech/blog/en/2021/reading-from-external-memory/" rel="external nofollow noreferrer" target=_blank> <img src=/images/index/twitter.svg alt="Share on Twitter" title="Share on Twitter" class="social-icon rounded-circle img-fluid w-100 p-1"> </a> <a class="d-block mb-2" href="https://news.ycombinator.com/submitlink?t=A%20journey%20to%20io_uring%2C%20AIO%20and%20modern%20storage%20devices&u=https%3A//clickhouse.tech/blog/en/2021/reading-from-external-memory/" rel="external nofollow noreferrer" target=_blank> <img src=/images/index/hackernews.svg alt="Share on HackerNews" title="Share on Hacker News" class="rounded-circle img-fluid w-100 p-1"> </a> <a class="d-block mb-2" href="http://www.reddit.com/submit?title=A%20journey%20to%20io_uring%2C%20AIO%20and%20modern%20storage%20devices&url=https%3A//clickhouse.tech/blog/en/2021/reading-from-external-memory/" rel="external nofollow noreferrer" target=_blank> <img src=/images/index/reddit.svg alt="Share on Reddit" title="Share on Reddit" class="invert-dark rounded-circle img-fluid w-100 p-1"> </a> </div> </section> </div> <section class="col-md-10 offset-md-1 my-5"> <span title="Published date" class="d-inline-block bg-dark text-white p-2 mr-2">2021-03-09</span> <div class="tag d-inline-block bg-light p-2 mr-2"> Linux </div> <div class="tag d-inline-block bg-light p-2 mr-2"> benchmark </div> <div class="tag d-inline-block bg-light p-2 mr-2"> experiment </div> </section> </div> </div> </div> </div> <div class=comments-bg> <div class=container> <div class=row> <section class="col-md-10 offset-md-1 my-5"> <div id=embedd-comments></div> </section> </div> </div> </div> <div class=container> <div class=row> <script async type=text/javascript src=/js/embedd.min.js?b030bfedd7></script> <div class=container> <div class=row> <div class=col> <div id=content-footer class="text-muted pt-3 mb-5"> <div class=float-md-right>©2016–2020 Yandex LLC</div> </div> </div> </div> </div> </div> </div> <script async type=text/javascript src=/js/base.js?00223b07></script> <noscript> <div><img src=https://mc.yandex.ru/watch/18343495 alt=Yandex></div> </noscript> </body> </html>